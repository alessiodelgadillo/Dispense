\chapter{DBMS}

Un DBMS è un sistema software che gestisce grandi quantità di dati persistenti e condivisi.\
La gestione di \textbf{grandi quantità di dati} richiede particolare attenzione ai problemi di \textit{efficienza} (ottimizzazione delle richieste, ma non solo).\
La \textbf{persistenza} e la \textbf{condivisione} richiedono che un DBMS fornisca dei meccanismi per garantire l'\textit{affidabilità} dei dati (fault tolerance), per il \textit{controllo degli accessi} e per il \textit{controllo della concorrenza}.\

Diverse altre funzionalità vengono messe a disposizione per motivi di \textbf{efficacia}, ovvero per semplificare la descrizione dei dati, lo sviluppo delle applicazioni, l'amministrazione di un DB, ecc.\

\subsubsection{Condivisione dei dati}

La \textbf{gestione integrata} e la \textbf{condivisione dei dati} permettono di evitare ripetizioni (ridondanza dovuta a copie multiple dello stesso dato), e quindi un inutile spreco di risorse (memoria).\
Inoltre, la \textbf{ridondanza} può dar luogo a problemi di \textbf{inconsistenza} delle copie e, in ogni caso, comporta la necessità di \textit{propagare} le modifiche, con un ulteriore spreco di risorse (CPU e rete).\

\subsubsection{Il modello dei dati}

Dal punto di vista utente un DB è visto come una collezione di dati che modellano una certa porzione della realtà di interesse.\
L'\textbf{astrazione logica} con cui i dati vengono resi disponibili all'utente definisce un \textbf{modello dei dati}, più precisamente:

\vspace{12pt}
\noindent\textit{un modello dei dati è una collezione di concetti che vengono utilizzati per descrivere i dati, le loro associazioni/relazioni e i vincoli che questi devono rispettare}.\
\vspace{12pt}

\noindent Un ruolo di primaria importanza nella definizione di un modello dei dati è svolto dai \textbf{meccanismi che possono essere usati per strutturare i dati}.\
Ad esempio esistono modelli in cui i dati sono descritti (solo) sotto forma di alberi (modello \textit{gerarchico}), di grafi (modello \textit{reticolare}), di oggetti complessi (modello \textit{a oggetti}), di relazioni (modello \textit{relazionale}).

\subsubsection{Indipendenza fisica e logica}

Tra gli obiettivi di un DBMS vi sono quelli di fornire caratteristiche di:
\begin{itemize}
	\item \textbf{Indipendenza fisica}:\ l'\textit{organizzazione fisica} dei dati dipende da considerazioni legate all'efficienza delle organizzazioni adottate.\ La riorganizzazione fisica dei dati \textit{non deve comportare effetti collaterali sui programmi applicativi}.
	\item \textbf{Indipendenza logica}:\ permette di accedere ai dati logici indipendentemente dalla loro rappresentazione fisica.
\end{itemize}

\section{Gerarchia delle memorie}

La memoria di un sistema di calcolo è organizzata in una gerarchia:\ al livello più alto memorie di piccola dimensione, molto veloci, costose; scendendo lungo la gerarchia la dimensione aumenta, diminuiscono la velocità e il costo.\

Dato un indirizzo di memoria, le prestazioni si misurano in termini di tempo di accesso, determinato dalla somma della latenza (tempo necessario per accedere al primo byte) e del tempo di trasfe\-rimento (tempo necessario per muovere i dati).\

\[\mathrm{Tempo\ di\ accesso = latenza + \frac{dim.\ dati\ da\ trasferire}{ veloc.\ di\ trasferimento}}\]

\subsubsection{Implicazioni per i DBMS}

Un DB, a causa della sua dimensione, risiede normalmente su dischi (ed eventualmente anche su altri tipi di dispositivi):\ i dati devono essere trasferiti in memoria centrale per essere elaborati dal DBMS.\
\textit{Il trasferimento non avviene in termini di singole tuple, bensì di blocchi} o \textit{pagine}\footnote{\textbf{Pagine}:\ termine comunemente usato quando i dati sono in memoria.}; poiché spesso le operazioni di I/O costituiscono il collo di bottiglia del sistema, si rende necessario ottimizzare l'implementazione fisica del DB, attraverso un'organizzazione efficiente delle tuple su disco, strutture di accesso efficienti, gestione efficiente dei buffer in memoria e delle strategie di esecuzione efficienti per le query.

\subsection{Gli Hard Disk}

Un hard disk (HD) è un dispositivo elettro-meccanico per la conservazione di informazioni sotto forma magnetica, su supporto rotante a forma di piatto su cui agiscono delle testine di lettura/scrittura.\

Il meccanismo del disk drive include organi di registrazione, di posizionamento e di rotazione:\ un'unità a dischi contiene una pila di dischi metallici che ruota a velocità costante ed alcune testine di letture che si muovono radialmente al disco.\
Una \textbf{traccia} è organizzata in settori di dimensione fissa; i settori sono raggruppati logicamente in \textbf{blocchi}, che sono l'unità di trasferimento.\
Trasferire un blocco richiede un tempo di posizionamento delle testine, un tempo di latenza rotazionale e tempo per il trasferimento (trascurabile).\

\subsubsection{Pagine}

Un blocco (o \textbf{pagina}) è una \textbf{sequenza contigua di settori su una traccia e costituisce l'unità di I/O per il trasferimento di dati da/per la memoria principale}.\
La dimensione tipica di una pagina è di qualche KB (4-64 KB):\ pagine piccole comportano un maggior numero di operazioni di I/O, mentre pagine grandi tendono ad aumentare la frammentazione interna (pagine parzialmente riempite) e richiedono più spazio in memoria per essere caricate.\
Il \textit{tempo di trasferimento di una pagina} (\textbf{T\textsubscript{t}}) da disco a memoria centrale dipende dalla dimensione della pagina (\textbf{P}) e dal transfer rate (\textbf{T\textsubscript{r}}).

\subsection{Gestore della memoria permanente e gestore del buffer}

\textbf{Gestore memoria permanente}:\ fornisce un'astrazione della memoria permanente in termini di insiemi di file logici di pagine fisiche di registrazioni (blocchi), nascondendo le caratteristiche dei dischi e del sistema operativo.\
\textbf{Gestore del buffer}:\ si preoccupa del trasferimento delle pagine tra la memoria temporanea e la memoria permanente, offrendo agli altri livelli una visione della memoria permanente come un insieme di pagine utilizzabili in memoria temporanea, astraendo da quando esse vengano trasferite dalla memoria permanente al buffer e viceversa.\
Usa una tabella associativa per mantenere la relazione $\langle \mathtt{idPage, posBuffer}\rangle$.\
Inoltre, ad ogni pagina è associato un \textbf{\textit{dirty} bit}, indica se la pagina è stata modificata o meno e di conseguenza se deve essere aggiornata sul disco, e un \textbf{pin count}, un contatore che viene incrementato/decrementato ogni volta che una pagina viene richiesta/rilasciata.\

\begin{itemize}
	\item \texttt{getAndPinPage}:\ richiede la pagina al buffer manager e vi pone un pin (``spillo''), ad indicarne l'uso.
	\item \texttt{unPinPage}: rilascia la pagina e elimina un pin.
	\item \texttt{setDirty}:\ indica che la pagina è stata modificata, ovvero è dirty (``sporca'').
	\item \texttt{flushPage}:\ forza la scrittura della pagina su disco, rendendola così ``pulita''.
\end{itemize}

\subsubsection{Politiche di rimpiazzamento}

Nei sistemi operativi una comune politica adottata per decidere quale pagina rimpiazzare è la LRU (\textit{Least Recently Used}), ovvero si rimpiazza la pagina che non è in uso da più tempo.\
Nei DBMS, LRU non è sempre una buona scelta, in quanto per alcune query il ``pattern di accesso'' ai dati è noto e può quindi essere utilizzato per operare scelte più accurate in grado di migliorare anche di molto le prestazioni.\

L'hit ratio, ovvero la frazione di richieste che non provocano una operazione di I/O, indica sinteticamente quanto buona è una politica di rimpiazzamento; ad esempio esistono algoritmi di \texttt{join} che scandiscono $N$ volte le tuple di una relazione:\ in questo caso la politica migliore sarebbe la MRU (\textit{Most Recently Used}), ovvero rimpiazzare la pagina usata più di recente!\

\vspace{12pt}
\noindent\dots altro motivo per cui i DBMS non usano (tutti) i servizi offerti dai sistemi operativi\dots

\subsubsection{Struttura di una pagina}

\begin{flushleft}
	Struttura fisica:\ un insieme, di dimensione fissa, di caratteri.

	Struttura logica:\ informazioni di servizio, area che contiene le stringhe che rappresentano i record.
\end{flushleft}

\noindent Una \textbf{directory} contiene \textit{un puntatore per ogni record nella pagina}; con questa soluzione l'\textbf{identificatore di un record} (\textbf{RID}) nel DB è formato da una coppia:
\begin{itemize}
	\item \textbf{PID}:\ identificatore della pagina.
	\item \textbf{Slot}:\ posizione all'interno della pagina.
\end{itemize}

\noindent È possibile sia individuare velocemente un record, sia permettere la sua rial\-locazione nella pagina senza modificare il RID.\

\section{Gestore delle strutture di memorizzazione}

\subsection{Organizzazione seriale e sequenziale}

Organizzazione \textbf{seriale} (\textbf{heap} file):\ i dati sono memorizzati in modo disordinato uno dopo l'altro; è semplice e a basso costo di memoria, tuttavia è poco efficiente e va bene solo per pochi dati.\
È l'organizzazione standard di ogni DBMS.

\vspace{12pt}

\noindent Organizzazione \textbf{sequenziale}:\ i dati sono \textit{ordinati} sul valore di uno o più attributi ottenendo ricerche più veloci; tuttavia le nuove inserzioni fanno perdere l'ordinamento.

La ricerca binaria su file di dati ordinato richiede $\log_2 b$ \textit{accessi a blocco{\slash}pa\-gina}.\
Se il file contiene $b_i$ blocchi, la localizzazione di un record richiede la ricerca binaria nel file e l'accesso al blocco che contiene il record; quindi richiede $\log_2 b_i + 1$ \textit{accessi a blocco{\slash}pagina}.

\subsection{Organizzazione per chiave}

\textbf{Obiettivo}:\ noto il valore di una chiave, trovare il record di una tabella con qualche accesso al disco (idealmente un accesso).\
\textbf{Alternative}:
\begin{itemize}
	\item Metodo procedurale (hash) o tabellare (indice).
	\item Organizzazione statica o dinamica.
\end{itemize}

\subsubsection{Hash File}

In un file hash \textit{i record vengono allocati in una pagina il cui indirizzo dipende dal valore di chiave del record}:\
\[\mathrm{key \rightarrow H(key) \rightarrow page\ address}\]
Una comune funzione hash è il \textit{resto della divisione intera}:
\[H(k) = k\ mod\ \mathit{NP}\]
\noindent Si può applicare anche a chiavi alfanumeri che dopo averle convertite.\
L'insieme delle chiavi è molto più grande dell'insieme dei possibili valori dell'indice.\

\subsubsection{Metodo procedurale statico}

Parametri di progetto:\
\begin{itemize}
	\item la funzione per la trasformazione della chiave;
	\item il \textbf{fattore di caricamento}
	      \[d=\frac{N}{M\cdot c}\]
	      Frazione dello spazio fisico disponibile mediamente utilizzata.\ Se \textbf{\textit{N} è il numero di tuple} previsto per il file, \textbf{\textit{M} il fattore di pagine} e \textbf{\textit{c} il fattore di caricamento}, il file può prevedere un \textbf{numero di blocchi \textit{B}} pari al numero intero immediatamente superiore a \textbf{\textit{d}};
	\item la capacità $c$ delle pagine;
	\item il metodo per la gestione dei trabocchi.
\end{itemize}

\noindent Le collisioni (overflow) sono di solito gestite con \textit{linked list}, è l'organizzazione più efficiente per l'accesso diretto basato su valori della chiave con condizioni di uguaglianza (\textbf{accesso puntuale}); non è efficiente per \textit{ricerche basate su intervalli} (n.\ per ricerche basate su altri attributi).\
Funzionano solo con file la cui dimensione non varia molto nel tempo (procedurale \textbf{statico}).\

\subsubsection{Metodo tabellare}

Il metodo procedurale (hash) è utile per ricerche per chiave ma non per in\-tervallo.\
Per entrambi i tipi di ricerche è utile invece il \textbf{metodo tabellare}:\ si usa un \textit{indice}\footnote{\textbf{Indice}:\ struttura che contiene \textit{informazioni sulla posizione di memorizzazione delle tuple} sulla base del valore del campo chiave}, ovvero un \textit{insieme ordinato} di coppie $\langle k, r(k)\rangle$, dove $k$ è un valore della chiave ed $r(k)$ è un riferimento al record con chiave $k$.\

L'indice è gestito di solito con un'opportuna struttura albero detta $B^+$\textit{-tree}, la struttura più usata e ottimizzata dai DBMS.\
Gli indici possono essere multi-attributi.\

\subsection{B\textsuperscript{+}-tree}

\subsubsection{Albero binario di ricerca}

Albero binario etichettato in cui per ogni nodo, il sottoalbero sinistro contiene solo etichette minori di quella del nodo e il sottoalbero destro etichette maggiori.\
Tempo di ricerca (e inserimento), pari alla profondità:\ logaritmico nel caso ``medio'' (assumendo un ordine di inserimento casuale).\

\subsubsection{Albero di ricerca di ordine P}

Ogni nodo ha (fino a) $P$ figli e (fino a) $P-1$ etichette ordinate:\ un albero di ricerca di ordine $p$ è un albero i cui nodi contengono al più $p-1$ \textit{search value} e $P$ \textit{puntatori} nel seguente ordine
\[\langle P_1, K_1, P_2, K_2,\dots, P_{q-1}, K_{q-1}, P_q\rangle\qquad  \mathrm{con}\ q \leq p\]
Ogni $P_i$ è un puntatore ad un nodo figlio (o un puntatore nullo) e ogni $K_i$ è un \textit{search value} appartenente ad un insieme totalmente ordinato.\
Ogni albero di ricerca deve soddisfare due vincoli fondamentali:
\begin{enumerate}
	\item ogni nodo $K_1 < K_2 < \dots < K_{q-1}$;
	\item per tutti i valori di $X$ presenti nel sottoalbero puntato da $P_i$, vale che \[K_{i-1} < X < K_i\quad \mathrm{per}\ 1 < i < q\] \[X < K_i\quad \mathrm{per}\ i = 1\] \[K_{i-1} < X \quad\mathrm{per}\ i = q\]
\end{enumerate}

\noindent Un albero di ricerca può essere utilizzato per cercare record memorizzati su disco.\
\textbf{Ogni ricerca/modifica comporta la visita di un cammino radice foglia}.\
I valori di ricerca (\textit{search value}) possono essere i valori di uno dei campi del file (\textit{search field}) e ad ogni valore di ricerca è associato un puntatore al record avente quel valore (oppure al blocco contenente quel record) nel file di dati.\

L'albero stesso può essere memorizzato su disco, assegnando ad ogni nodo dell'albero una \textbf{pagina}:\ quando un nuovo record deve essere inserito, l'albero di ricerca deve essere aggiornato includendo il valore del campo di ricerca del nuovo record, col relativo puntatore al record (o alla pagina che lo contiene) nell'albero di ricerca.

Per inserire/cancellare valori di ricerca nell'albero di ricerca sono necessari specifici algoritmi che garantiscano il rispetto dei due vincoli fondamentali.\
In generale, tali algoritmi non garantiscono che un albero di ricerca risulti sempre bilanciato (nodi foglia tutti allo stesso livello) $\rightarrow$ soluzione:\ B-tree e B\textsuperscript{+}-tree.\

\subsubsection{B-tree}

Un B-tree di ordine $p$, se usato come struttura di accesso su un campo chiave per la ricerca di record in un file di dati, deve soddisfare le seguenti condizioni:\
\begin{itemize}
	\item ogni nodo interno del B-tree ha la forma \[\langle P_1, \langle K_1, Pr_1\rangle, P_2, \langle K_2, Pr_2\rangle, \dots, \langle K_{q-1}, Pr_{q-1}\rangle, P_q\rangle \quad  \mathrm{con}\ q \leq p_1\] dove $P_i$ è un \textbf{\textit{tree pointer}} (puntatore ad un altro nodo del B-tree), $K_i$ è la \textbf{\textit{chiave di ricerca}} e $Pr_i$ è un \textbf{\textit{data pointer}} (puntatore ad un record il cui campo chiave di ricerca è uguale a $K_i$ o alla pagina che contiene tale record);
	\item per ogni nodo, si ha che \[K_1 < K_2 < \dots < K_{q-1}\]
	\item ogni nodo ha al più $p$ \textit{tree pointer};
	\item per tutti i valori $X$ della chiave di ricerca appartenenti al sottoalbero puntato da $P_i$, si ha che \[K_{i-1} < X < K_i\quad\mathrm{per}\ 1 < i < q\] \[X < K_i\quad\mathrm{per}\ i = 1\] \[K_{i-1} < X\quad\mathrm{per}\ i = q\]
	\item ogni \textbf{nodo}, esclusa la radice, ha almeno $\lceil \frac{p}{2}\rceil$ \textit{tree pointer};
	\item la \textbf{radice} ha almeno due \textit{tree pointer}, a meno che non sia l'unico nodo dell'albero;
	\item un nodo con $q$ \textit{tree pointer}, $q \leq p$, ha $q-1$ campi chiave di ricerca (e $q-1$ data pointer);
	\item \textbf{tutti i nodi foglia sono posti allo stesso livello} (i nodi foglia hanno la stessa struttura dei nodi interni, ad eccezione del fatto che tutti i loro tree pointer $P_i$ sono nulli).
\end{itemize}

\subsubsection{B\textsuperscript{+}-tree}

Un $\mathrm{\mathbf{B^+\textrm{-}tree}}$ è un B-tree in cui \textit{i data pointer sono memorizzati solo nei nodi foglia dell'albero}.\
La struttura dei nodi foglia differisce da quella dei B-tree e quindi da quella dei nodi interni.\

\textit{Se il campo di ricerca è un campo chiave}, i nodi foglia hanno per ogni valore del campo di ricerca una entry e un puntatore ad un record.\

\textit{Se un campo di ricerca non è un campo chiave}, i puntatori indirizzano un blocco che contiene i puntatori ai record del file di dati, rendendo così necessario un passo aggiuntivo per l'accesso ai dati.\

\textit{I nodi foglia di un $B^+\textrm{-}tree$ sono generalmente messi fra loro in relazione}; ciò viene sfruttato nel caso di rangequery:\ essi corrispondono al primo livello di un indice, mentre i nodi interni corrispondono agli altri livelli di un indice.\

Alcuni valori del campo di ricerca presenti nei nodi foglia sono ripetuti nei nodi interni per guidare la ricerca.

\vspace{12pt}
\noindent La struttura dei \textbf{nodi interni} (di ordine $p$) di un $\mathrm{B^+\textrm{-}tree}$ è la seguente:
\begin{enumerate}
	\item ogni nodo interno ha la forma \[\langle P_1, K_1, P_2, K_2, \dots, P_{q-1}, K_{q-1}, P_q \rangle \quad \mathrm{con}\ q \leq p\] dove ogni $P_i$ è un \textit{tree pointer}(puntatore ad un altro nodo)
	\item per ogni nodo interno, si ha che \[K_1 < K_2 < \dots < K_{q-1}\]
	\item ogni nodo interno ha al più $p$ tree pointer;
	\item per tutti i valori $X$ della \textit{search key} nel sottoalbero puntato da $P_i$, si ha che \[X \leq K_i\quad\mathrm{per}\ i = 1\]\[K_{i-1} < X \leq K_i\quad\mathrm{per}\ 1 < i < q\]\[K_{i-1} < X\quad\mathrm{per}\ i = q\]
	\item ogni nodo interno ha almeno $\lceil \frac{p}{2}\rceil$ tree pointer, mentre la radice ha almeno 2 tree pointer se è un nodo interno;
	\item un nodo interno con $q$ tree pointer, con $q \leq p$, ha $q-1$ campi di ricerca.
\end{enumerate}

\vspace{12pt}
\noindent La struttura dei nodi \textbf{foglia} (di ordine $p_{leaf}$) di un $\mathrm{B^+\textrm{-}tree}$ è la seguente:
\begin{enumerate}
	\item ogni nodo foglia è della forma \[\langle \langle K_1, Pr_1\rangle, \langle K_2, Pr_2\rangle, \dots, \langle K_q, Pr_q \rangle P_{next}\rangle\] dove $q \leq p_{\mathit{leaf}}$ e per ogni nodo si ha che $K_1 < K_2 < \dots < K_q$.
	      \begin{itemize}
		      \item $P_{next}$ è un \textit{tree pointer che punta al successivo nodo foglia} del $\mathrm{B^+\textrm{-}tree}$;
		      \item ogni $Pr_i$ è un \textit{data pointer che punta al record con valore del campo di ricerca uguale a $K_i$ o ad un blocco contenente tale record} (o ad un blocco di puntatori ai record con valore del campo di ricerca uguale a $K_i$, se il campo di ricerca non è una chiave);
	      \end{itemize}
	\item ogni nodo foglia ha almeno $\lceil\frac{p_{leaf}}{2}\rceil$ valori;
	\item tutti i nodi foglia sono dello stesso livello.
\end{enumerate}

\subsection{Indici e B\textsuperscript{+}-tree}

Di solito un \textbf{indice è organizzato a B\textsuperscript{+}-tree} per permettere di trovare con pochi accessi, a partire da un valore $v$, i record di $R$ in cui il valore di $A$ è in una relazione specificata con $v$.\
Esistono due tipologie di indici ad albero
\begin{itemize}
	\item\textbf{statici}:\ \textit{la struttura ad albero viene creata sulla base dei dati presenti nel DB} e non più modificata (o modificata periodicamente);
	\item\textbf{dinamici}:\ \textit{la struttura ad albero viene aggiornata ad ogni operazione} sulla base di dati di inserimento o di cancellazione, memorizzati, preservando le prestazioni senza bisogno di riorganizzazioni.
\end{itemize}

\noindent Inoltre si possono distinguere indici \textbf{primari}, in questo caso la chiave di or\-dinamento del file sequenziale coincide con la \textit{chiave di ricerca dell'indice}, e \textbf{secondari}, in questo caso invece la \textit{chiave di ordinamento} e la chiave di ricerca sono diverse.

Un indice può essere \textit{definito su di un insieme $A_1, \dots, A_n$ di attributi}.\
In questo caso l'indice contiene un record per ogni combinazione di valori assunti dagli attributi $A_1, \dots, A_n$ nella relazione e può essere utilizzato per rispondere in modo efficiente ad interrogazioni che specifichino un valore per ciascuno di questi attributi.

\subsubsection{Indice primario}

Un indice \textbf{primario} è un file ordinato i cui record sono di lunghezza fissa e sono costituiti da due campi:\ il primo campo è dello stesso tipo del campo \textit{chiave di ordinamento} (chiave primaria), mentre il secondo campo è un \textit{puntatore a un blocco del disco}.\

Esiste un record nel file dell'indice per ogni blocco nel file di dati.

\subsubsection{Indice secondario}

Un indice \textbf{secondario} può essere definito su un \textit{campo non chiave} che è una chiave \textit{candidata} e ha valori univoci, o su un campo non chiave con \textit{valori duplicati}.\
Il primo campo è dello stesso tipo del campo che non viene usato per ordinare il file ed è chiamato \textit{campo di indicizzazione}, il secondo campo è un \textit{puntatore al blocco} oppure un \textit{puntatore al record} (RID).\

\section{Ordinamento di archivi}

L'algoritmo più comunemente utilizzato dai DBMS è quello detto di \textbf{Merge Sort} a Z vie (Z-way Sort-Merge).\
Supponiamo di dover ordinare un input che consiste di un file di \textit{NP pagine} e di avere a disposizione solo $\mathbf{NB} < \mathit{NP}$ \textbf{buffer} in memoria centrale.\
L'algoritmo opera in 2 fasi:
\begin{itemize}
	\item \textit{Sort interno}:\ si leggono una alla volta le pagine del file; i record di ogni pagina vengono ordinati facendo uso di un algoritmo di sort interno (es.\ quick-sort); ogni pagina così ordinata, detta anche ``\textit{run}'', viene scritta su disco in un file temporaneo.
	\item \textit{Merge}:\ operando uno o più passi di fusione, le \textit{run} vengono fuse, fino a produrre un'unica \textit{run}.
\end{itemize}

\subsubsection{Caso base}
Per semplicità si consideri il caso base a $Z = 2$ vie e si supponga di avere a disposizione solo $\mathit{NB} = 3$ buffer in memoria centrale.\

Nel caso base $Z = 2$ si fondono 2 run alla volta; con $\mathit{NB} = 3$, si associa un buffer a ognuna delle run, il terzo buffer serve per produrre l'output, una pagina alla volta:\ si legge la prima pagina da ciascuna run e si può quindi determinare la prima pagina dell'output; quando tutti i record di una pagina di run sono stati consumati, si legge un'altra pagina della run.

Si consideri per semplicità solo il \textbf{numero di operazioni di I/O}; si può osservare che:\
\begin{itemize}
	\item nella fase di sort interno si leggono e si riscrivono \textit{NP} pagine,
	\item ad ogni passo di merge si leggono e si riscrivono \textit{NP} pagine ($2 \cdot \mathit{NP}$); il numero di passi fusione è pari a $\lceil \log_2\mathit{NP}\rceil$, in quanto ad ogni passo il numero di run si dimezza.
\end{itemize}

\noindent Il costo complessivo è pertanto pari a $2 \cdot \mathit{NP} \cdot \left(\lceil\log_2\mathit{NP}\rceil + 1\right)$.

\noindent In realtà se \textit{NP} non è una potenza di 2 il numero effettivo di I/O è leggermente minore di quello calcolato, in quanto in uno o più passi di fusione può capitare che una run non venga fusa con un'altra.

\subsubsection{Caso generale}

Una prima osservazione è che nel passo di sort interno, avendo a disposizione \textit{NB} buffer, si possono ordinare \textit{NP} pagine alla volta (anziché una sola), il che porta a un costo di \[2 \cdot \mathit{NP} \cdot \left(\left\lceil\log_2\left(\frac{\mathit{NP}}{\mathit{NB}}\right)\right\rceil+ 1\right)\]

\noindent Miglioramenti sostanziali si possono ottenere se, avendo $\mathit{NB} > 3$ buffer a disposizione, si fondono $\mathit{NB} - 1$ run alla volta (un buffer è per l'output).\
In questo caso il numero di passi di fusione è logaritmico in $\mathit{NB} - 1$, ovvero è pari a \[2 \cdot \mathit{NP} \cdot \left(\left\lceil\log_{\mathit{NB}-1}\left(\frac{\mathit{NP}}{\mathit{NB}}\right)\right\rceil+ 1\right)\]

\subsection{Realizzazione degli operatori relazionali}

Oltre che per ordinare le tuple, il sort può essere utilizzato per le query in cui compare l'opzione \texttt{DISTINCT}, ovvero per eliminare i duplicati, e per le query che contengono la clausola \texttt{GROUP BY}.\
Caso di \texttt{DISTINCT}:
\begin{enumerate}
	\item si legge R e si scrive T che contiene solo gli attributi della \texttt{SELECT},
	\item si ordina T su tutti gli attributi,
	\item si eliminano i duplicati.
\end{enumerate}

\noindent Caso di \texttt{GROUP BY}:\ si ordinano i dati sugli attributi del \texttt{GROUP BY}, poi si visitano i dati e si calcolano le funzioni di aggregazione per ogni gruppo.

Un'altra situazione in cui il sort può essere usato è per il prodotto cartesiano.\ $R\times S$ è grande; pertanto, $R\times S$ seguito da una restrizione è inefficiente.\
Anche se il \texttt{Join} è logicamente commutativo, dal punto di vista fisico vi è una chiara distinzione, che influenza anche le prestazioni, tra operando sinistro (o ``esterno'', ``outer'') e operando destro (o ``interno'', ``inner'').

\subsubsection{Nested Loops}

\begin{table}[H]
	\centering
	\begin{tabular}{|l|}
		\hline
		foreach \textbf{record} $r \in R$ do                     \\
		\quad foreach \textbf{record} $s \in S$ do               \\
		\qquad if $r_i = s_j$ then                               \\
		\qquad\quad aggiungi $\langle r, s \rangle$ al risultato \\\hline
	\end{tabular}
\end{table}

\noindent Il costo di esecuzione dipende dallo spazio a disposizione in memoria centrale.\
Nel caso base in cui vi sia un buffer per R e un buffer per S, bisogna leggere una volta R e $\mathit{Nrec}(R)$ volte S, ovvero tante volte quante sono le tuple della relazione esterna, per un totale di \[Npag(R) + Nrec(R) \cdot Npag(S)\ \mathrm{I/O}\]
Se è possibile allocare $Npag(S)$ buffer per la relazione interna il costo si riduce a $Npag(R) + Npag(S)$.

\begin{flushleft}
	Costo con R esterno: \[Npag(R) + Nrec(R) \cdot Npag(S) \approx Npag(R)\cdot\frac{Nrec(R)}{Npag(R)}\cdot Npag(S)\]
	Costo con S esterno: \[Npag(S) + Nrec(S) \cdot Npag(R) \approx Npag(S)\cdot\frac{Nrec(S)}{Npag(S)}\cdot Npag(R)\]
\end{flushleft}

\noindent Si sceglierà R come esterna e S come interna se \[\frac{Nrec(R)}{Npag(R)} < \frac{Nrec(S)}{Npag(S)}\] che corrisponde a dire che le tuple di R sono più grandi di quelle di S.\

\begin{center}
	\textit{Come esterna conviene la relazione con record più lunghi/grandi.}
\end{center}

\noindent L'ordine con cui vengono generate le tuple del risultato coincide con l'ordine eventualmente presente nella relazione esterna.\
Pertanto se l'ordine che si genera è ``interessante'', ad esempio perché la query contiene \texttt{ORDER BY R.A}, la scelta della relazione esterna può risultarne influenzata.\

\subsubsection{Nested loop a pagine}

Molti DBMS usano una variante del Nested Loops, detta Nested loop a pagine (\textit{PageNestedLoop}), che, rinunciando a preservare l'ordine della relazione esterna, risulta più efficiente in quanto esegue il \texttt{join} \textit{di tutte le tuple in memoria prima di richiedere nuove pagine della relazione interna}.\

\begin{table}[H]
	\centering
	\begin{tabular}{|l|}
		\hline
		foreach \textbf{pagina} $p_r$ di R do                             \\
		\quad foreach \textbf{pagina} $p_s$ di S do                       \\
		\qquad esegui il \texttt{join} di tutte le tuple in $p_r$ e $p_s$ \\\hline
	\end{tabular}
\end{table}

\begin{flushleft}
	Il costo è ora pari a $\mathit{NP}(R) + \mathit{NP}(R) \cdot \mathit{NP}(S)$.
\end{flushleft}

\noindent La strategia si estende anche al caso in cui a R siano assegnati più buffer.\

\subsubsection{Nested loop con indice (IndexNestedLoop)}

Data una tupla della relazione esterna R, la scansione completa della relazione interna S può essere sostituita da una scansione basata su un indice costruito sugli attributi di \texttt{join} di S, secondo il seguente schema

\begin{table}[H]
	\centering
	\begin{tabular}{|l|}
		\hline
		foreach \textbf{record} $r \in R$ do                                        \\
		\quad usa l'indice su $j$ per trovare tutti i record $s \in S\ |\ s_j =r_j$ \\
		\quad aggiungi $\langle r,s\rangle$ al risultato                            \\\hline
	\end{tabular}
\end{table}

\noindent L'accesso alla relazione interna mediante indice porta in generale a ridurre di molto i costi di esecuzione del Nested Loops Join.

\subsubsection{Sort Merge}

Il Sort-merge Join è applicabile quando entrambi \textit{gli insiemi di tuple in input sono \textbf{ordinati} sugli attributi di join}.\
Per R(S) ciò è possibile se:
\begin{itemize}
	\item R(S) è fisicamente ordinata sugli attributi di join,
	\item esiste un indice sugli attributi di join di R(S).
\end{itemize}

\begin{table}[H]
	\centering
	\begin{tabular}{|l|}
		\hline
		$r=\mathit{first}(R); s =\mathit{first}(R)$           \\
		while $r\in R \land s \in S$ do                       \\
		\quad if $r_i =s_j$                                   \\
		\qquad avanza $r$ ed $s$ fino a che $r_i$ e $s_j$ non \\
		\qquad cambiano entrambe, aggiungendo                 \\
		\qquad ciascun $\langle r,s\rangle$ al risultato      \\
		\quad else if $r_i <s_j$ avanza $r$ dentro $R$        \\
		\quad else if $r_i > s_j$ avanza $s$ dentro $S$       \\\hline
	\end{tabular}
\end{table}

\noindent La logica dell'algoritmo (senza considerare il tempo per il sort) sfrutta il fatto che entrambi gli input sono ordinati per evitare di fare inutili confronti, ciò fa sì che il numero di letture sia dell'ordine di $\mathit{Npag}(R) + \mathit{Npag}(S)$ se si accede sequenzialmente alle due relazioni.

\section{Piani di accesso}

L'ottimizzazione delle interrogazione è fondamentale nei DBMS.\
È necessario conoscere il funzionamento dell'ottimizzatore per una buona progettazione fisica.\
Obiettivo dell'ottimizzatore:\ scegliere il piano con costo minimo, fra possibili piani alternativi, usando le statistiche presenti nel catalogo.\

Un \textbf{piano di accesso} è un albero che descrive l'intero algoritmo che sarà usato per implementare l'interrogazione desiderata.\
Le foglie sono le tabelle ed i nodi interni specificano le modalità (operatori fisici) con cui gli accessi alle tabelle e le operazioni relazionali sono effettuate.\

\begin{flushleft}
	Ideale:\ trovare il piano migliore.\

	Euristica:\ evitare i piani peggiori!
\end{flushleft}

\subsection{Operatori fisici}

Gli algoritmi per realizzare gli operatori relazionali si codificano in opportuni operatori fisici, ad esempio \texttt{TableScan(R)} è l'operatore fisico per la scansione di R.\
Ogni operatore fisico è un \textbf{iteratore}, un \textit{oggetto} con metodi \textit{open}, \textit{next}, \textit{isDone}, \textit{reset} e \textit{close} realizzati usando gli operatori della macchina fisica, con \textit{next} che ritorna un record.\

\subsubsection{Interfaccia a iteratore}

DBMS definiscono gli operatori mediante un'interfaccia a ``iteratore'', i cui metodi principali sono:

\begin{itemize}
	\item \textbf{open}:\ \textit{inizializza} lo stato dell'operatore, \textit{alloca il buffer} per gli input e l'output, \textit{richiama ricorsivamente open sugli operatori figli}; viene anche usato per \textbf{\textit{passare argomenti}} (ad es.\ la condizione che un operatore \texttt{Filter} deve applicare).
	\item \textbf{next}:\ usato per richiedere un'altra ennupla del risultato dell'operatore; l'implementazione di questo metodo \textit{include next sugli operatori figli} e codice specifico dell'operatore.
	\item \textbf{close}:\ usato per \textit{terminare l'esecuzione} dell'operatore, con conseguente \textit{rilascio delle risorse} ad esso allocate.\
	\item \textbf{isDone}:\ indica se vi sono ancora valori da leggere, in genere è booleano.\
\end{itemize}

\noindent Un piano di accesso è un algoritmo per eseguire un'interrogazione usando gli operatori fisici disponibili.

\subsubsection{Operatori logici e fisici}

\begin{table}[H]
	\centering
	\begin{tabular}{|c|l|}
		\hline
		Operatore logico                    & Operatore fisico                                                \\\hline\hline
		\multirow{6}{2em}{$R$}              & \texttt{TableScan(R)}:                                          \\
		                                    & per la scansione di R.                                          \\\cline{2-2}
		                                    & $\mathtt{IndexScan(R, Idx)}$:                                   \\
		                                    & per la scansione di R con l'indice Idx.                         \\\cline{2-2}
		                                    & $\mathtt{SortScan(R, \{A_i\})}$:                                \\
		                                    & per la scansione di R ordinata sugli $\mathrm{\{A_i\}}$.        \\\hline
		\multirow{6}{3em}{$\pi_{\{A_i\}}$}  & $\mathtt{Project(O, \{A_i\}})$:                                 \\
		                                    & per la proiezione dei record di O senza                         \\
		                                    & l'eliminazione dei duplicati.                                   \\\cline{2-2}
		                                    & $\mathtt{Distinct(O)}$:                                         \\
		                                    & per eliminare i duplicati dei record ordinati                   \\
		                                    & di O.                                                           \\\hline
		\multirow{4}{2em}{$\sigma_\psi$}    & $\mathtt{Filter(O, \psi)}$:                                     \\
		                                    & per la restrizione senza indici dei record di O.                \\\cline{2-2}
		                                    & $\mathtt{IndexFilter(R, Idx, \psi)}$:                           \\
		                                    & per la restrizione con indice dei record di R.                  \\\hline
		\multirow{3}{2em}{$\tau_{\{A_i\}}$} & $\mathtt{Sort(O, \{A_i\}})$:                                    \\
		                                    & per ordinare i record di O sugli $\mathrm{\{A_i\}}$, per valori \\
		                                    & crescenti.                                                      \\\hline
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\begin{tabular}{|c|l|}
		\hline
		Operatore logico                                & Operatore fisico                                                      \\\hline\hline
		\multirow{8}{4em}{$_{\{A_i\}}\gamma_{\{f_i\}}$} & $\mathtt{GroupBy(O, \{A_i\}, \{f_i\})}$:                              \\
		                                                & per raggruppare i record di O sugli $\mathrm{\{A_i\}}$ usando le      \\
		                                                & funzioni di aggregazione in $\mathrm{\{f_i\}}$.                       \\
		                                                & - Nell'insieme $\mathrm{\{f_i\}}$ vi sono le funzioni di aggregazione \\
		                                                & \quad presenti nella \texttt{SELECT} e nella \texttt{HAVING}.         \\
		                                                & - L'operatore restituisce record con attributi gli $\mathrm{\{A_i\}}$ \\
		                                                & \quad e le funzioni in $\mathrm{\{f_i\}}$.                            \\
		                                                & - I record di O sono ordinati sugli $\mathrm{\{A_i\}}$.               \\\hline
		\multirow{16}{2em}{$\stackrel{\Join}{\psi_J}$}  & $\mathtt{NestedLoop(O_E, O_I, \psi_J)}$:                              \\
		                                                & per la giunzione con il \textit{nested loop} e $\psi_J$ la condizione \\
		                                                & di giunzione.                                                         \\\cline{2-2}
		                                                & $\mathtt{PageNestedLoop(O_E, O_I, \psi_J)}$:                          \\
		                                                & per la giunzione con il \textit{page nested loop}.                    \\\cline{2-2}
		                                                & $\mathtt{IndexNestedLoop(O_E, O_I, \psi_J)}$:                         \\
		                                                & per la giunzione con l'\textit{index nested loop}.                    \\
		                                                & L'operando interno $O_I$ è un $\mathtt{IndexFilter(R, Idx, \psi_J)}$  \\
		                                                & oppure $\mathtt{Filter(O,\psi')}$, con O un                           \\
		                                                & $\mathtt{IndexFilter(R, Idx, \psi_J)}$.                               \\
		                                                & Per ogni record $r$ di $O_E$, la condizione $\psi_J$                  \\
		                                                & dell'\texttt{IndexFilter} è quella di giunzione con                   \\
		                                                & gli attributi di $O_E$ sostituiti dai valori in $r$.                  \\\cline{2-2}
		                                                & $\mathtt{SortMerge(O_E, O_I, \psi_J)}$:                               \\
		                                                & per la giunzione con il \textit{sort-merge}, con i record di          \\
		                                                & $O_E$ e $O_I$ ordinati sugli attributi di giunzione.                  \\
		\hline
	\end{tabular}
\end{table}

\section{Transazioni}
\begin{center}
	\textit{Cos'è una transazione}?
\end{center}

\begin{definition}
	Una \textbf{transazione} è un'\textit{unità logica di elaborazione che corrisponde a una serie di operazioni fisiche elementari} (letture/scritture) sul DB.
\end{definition}

\noindent Le \textbf{transazioni} rappresentano l'unità di lavoro elementare (insiemi di istruzioni SQL) che \textit{modificano} il contenuto di una base di dati.\
Sintatticamente una transizione è contornata dai comandi \texttt{begin transaction} (e \texttt{end transaction}); all'interno possono comparire i comandi di \texttt{commit work} e \texttt{rollback work}.\

Proprietà \textbf{ACID} delle transizioni:
\begin{itemize}
	\item \textbf{A}tomicità $\rightarrow$ la transazione deve essere eseguita con la regola del ``tutto o niente''.
	\item \textbf{C}onsistenza $\rightarrow$ la transazione deve lasciare il DB in uno stato consistente, eventuali vincoli di integrità non devono essere violati.
	\item \textbf{I}solamento $\rightarrow$ l'esecuzione di una transazione deve essere indipendente dalle altre.
	\item Persistenza (\textbf{D}urability) $\rightarrow$ l'effetto di una transazione che ha fatto \texttt{commit work} non deve essere perso.
\end{itemize}

\noindent Una \textit{funzionalità} essenziale di un DBMS è la \textit{protezione dei dati} da malfunzionamenti e da interferenze dovute all'accesso contemporaneo ai dati di più utenti.\

Per il programmatore una transazione è un programma sequenziale costi\-tuito da operazioni che il sistema deve eseguire garantendo atomicità, con\-sistenza, serializzabilità e persistenza (ACID).

\noindent Gestore dell'affidabilità:
\begin{itemize}
	\item \textbf{Atomicità}:\ le transazioni che terminano in modo prematuro (\textit{aborted transactions}) sono trattate dal sistema come se non fossero mai iniziate; pertanto eventuali loro effetti sulla base di dati sono annullati.
	\item \textbf{Persistenza}:\ le modifiche sulla base di dati di una transazione terminata normalmente sono permanenti, cioè non sono alterabili da eventuali malfunzionamenti.\
\end{itemize}

\noindent Gestore della concorrenza:
\begin{itemize}
	\item \textbf{Serializzabilità}:\ nel caso di esecuzioni concorrenti di più transazioni, l'effetto complessivo è quello di una esecuzione seriale.
\end{itemize}

\noindent Per aumentare l'efficienza prestazionale, tutti i DBMS utilizzano un buffer temporaneo di informazioni in memoria principale, il quale viene periodicamente scritto su memoria secondaria, quindi è necessaria una comunicazione con il gestore del buffer.\

Una transazione può eseguire molte operazioni sui dati recuperati da una base di dati, ma al DBMS interessano solo quelle di \textit{lettura} o \textit{scrittura} della base di dati, indicate con $r_i[x]$ e $w_i[x]$.\
Un dato letto o scritto può essere un \textit{record}, un \textit{campo} di un record o una pagina.\
Per semplicità supporremo che sia una pagina.\
Un'operazione di lettura $r_i[x]$ comporta la lettura di una pagina nel buffer, se non già presente.\
Un'operazione di scrittura $w_i[x]$ comporta l'eventuale lettura nel buffer di una pagina e la sua modifica nel buffer, ma non necessariamente la sua scrittura in memoria permanente.\
Per questa ragione, in caso di malfunzionamento, si potrebbe perdere l'effetto dell'operazione.\

\subsubsection{Tipi di fallimento}

\textbf{Fallimenti di transazioni}:\ non comportano la perdita di dati in memoria temporanea né persistente (es.:\ violazione di vincoli, violazione di protezione, stallo).\

\noindent\textbf{Fallimenti di sistema}:\ comportano la perdita di dati in memoria temporanea non di dati in memoria persistente (es.:\ comportamento anomalo del sistema, caduta di corrente, guasti hardware sulla memoria centrale).

\noindent\textbf{Disastri}:\ comportano la perdita di dati in memoria persistente (es.:\ danneggiamento di periferica).

\subsection{Gestione delle transazioni}
Il gestore dell'affidabilità verifica che siano garantite le proprietà di \textbf{atomicità} e \textbf{persistenza} delle transazioni; quindi è responsabile dell'implementazione dei comandi di \texttt{begin transaction}, \texttt{commit} e \texttt{rollback}, di ripristinare il sistema dopo \textit{malfunzionamenti software} (\textbf{ripresa a caldo}), di ripristinare il sistema dopo \textit{malfunzionamenti hardware} (\textbf{ripresa a freddo}).

Il controllore di affidabilità utilizza un log, nel quale sono indicate tutte le \textbf{operazioni svolte dal DBMS}.\

\vspace{12pt}
\noindent Convenzioni notazionali:\ data una transazione T, indicheremo con B(T), C(T) e A(T) i record di \texttt{begin}, \texttt{commit} e \texttt{abort} relativi a T e con U(T, O, BS, AS), I(T, O, AS) e D(T, O, BS) i record di update, insert e delete, rispettivamente su un \textit{oggetto O}, dove BS è \textit{before state} e AS è \textit{after state}.\
\vspace{12pt}

\noindent I record del log associati ad una transazione, consentono di disfare e rifare le corrispondenti azioni sulla base di dati:
\begin{itemize}
	\item primitiva di \textbf{undo}:\ per \textit{disfare} un'azione su un oggetto O, è sufficiente ricopiare in O il valore BS (l'insert viene disfatto cancellando l'oggetto O);
	\item primitiva di \textbf{redo}:\ per \textit{rifare} un'azione su un oggetto O, è sufficiente ricopiare in O il valore AS (il delete viene rifatto cancellando l'oggetto O).
\end{itemize}

\noindent Il log si presenta come un file sequenziale suddiviso in record.\
Esistono due tipi di record:\
\begin{itemize}
	\item\textbf{di transazione}:\ tengono traccia delle operazioni svolte da ciascuna transizione sul DBMS.\ Per ogni transazione, un record di begin (B), record di insert (I), delete (D) e update (U) e un record di commit (C) o di abort (A).
	\item\textbf{di sistema}:\ tengono traccia delle operazioni di sistema (dump{\slash}check\-point).
\end{itemize}

\subsubsection{L'operazione di dump}

L'operazione di \textbf{dump} produce una copia completa della base di dati, effettuata in mutua esclusione con tutte le altre transazioni quando il sistema non è operativo.\
La copia viene memorizzata in memoria stabile (backup).\

Al termine del dump, viene scritto nel log un record di dump, che segnala l'avvenuta esecuzione dell'operazione in un dato istante.\
Il sistema riprende, quindi, il suo funzionamento normale.

\subsubsection{Protezione dei dati da malfuzionamenti}

\begin{itemize}
	\item Copia della BD (dump).
	\item Giornale/\textbf{log} durante l'uso della BD, il sistema registra nel giornale/log la storia delle azioni effettuate sulla BD dal momento in cui ne è stata fatta l'ultima copia.
\end{itemize}

\noindent All'interno del giornale/log si ha $\langle\mathtt{T, begin}\rangle$ e per ogni operazione di modifica viene memorizzata la transazione responsabile, il tipo di ogni operazione eseguita, la nuova e vecchia versione del dato modificato:\ \[\langle\mathtt{T,write, address, oldV, newV}\rangle\]
Segue $\langle\mathtt{T, commit}\rangle$ o $\langle\mathtt{T, abort}\rangle$.
\vspace{12pt}

\noindent Regole di scrittura del log
\begin{itemize}
	\item Regola Write Ahead Log (WAL) $\rightarrow$ la parte \textbf{\textit{BS}} (\textit{before state}) di ogni record di log deve essere scritta \textit{prima che la corrispondente operazione} venga effettuata nella base di dati.
	\item Regola di Commit Precedence $\rightarrow$ la parte \textbf{\textit{AS}} (\textit{after state}) di ogni record di log deve essere scritta nel log \textit{prima di effettuare} il \texttt{commit} della transazione.
\end{itemize}

\noindent Gli algoritmi si differenziano a seconda del modo in cui si trattano le scritture sulla BD e la terminazione delle transazioni:

\begin{itemize}
	\item Disfare - Rifare
	\item Disfare - Non Rifare
	\item Non Disfare - Rifare
	\item Non Disfare - Non Rifare
\end{itemize}

\noindent \textit{Ipotesi}:\ le scritture nel giornale vengono portate subito nella memoria permanente.

\subsubsection{Disfare}

Quando si portano le modifiche nella BD?\
Politica della \textbf{modifica \textit{libera}}:\ le modifiche \textit{possono} essere portate nella BD stabile prima che la transazione termini (disfare o \textit{steal}).\

Regola per poter disfare:\ prescrittura nel giornale (``\textbf{Log Ahead Rule}'' o ``\textbf{Write Ahead Log}''); \textit{se la nuova versione di una pagina rimpiazza la vecchia sulla BD stabile prima che la transazione abbia raggiunto il punto di commit, allora la vecchia versione della pagina deve essere portata prima sul giornale in modo permanente}.

\subsubsection{Rifare}

Come si gestisce la terminazione?\
\texttt{commit} \textbf{\textit{libero}}: una transazione può essere considerata terminata normalmente prima che tutte le modifiche vengano riportate nella BD stabile (occorre rifare).\

Regola per poter rifare una transazione:\ ``\textbf{Commit Rule}''; \textit{le modifiche (nuove versioni delle pagine) di una T devono essere portate stabilmente nel giornale prima che la transazione raggiunga il commit (condizione per rifare)}.

\subsubsection{Punto di allineamento}

Al momento del ripristino, solo gli aggiornamenti più recenti tra quelli riportati sul giornale{\slash}log potrebbero non essere stati ancora riportati sulla base di dati.\

Come ottenere la certezza che non sia necessario rieseguire le operazioni più vecchie?\
Periodicamente si fa un \textit{checkpoint} (\texttt{CKP}):\ si scrive la marca \texttt{CKP} sul giornale{\slash}log per indicare che tutte le operazioni che la precedono sono state effettivamente effettuate sulla BD.

\vspace{12pt}
\noindent Un modo (troppo semplice) per fare il \texttt{CKP}:
\begin{enumerate}
	\item si sospende l'attivazione di nuove transazioni,
	\item si completano le precedenti, si allinea la base di dati (ovvero si riportano su disco tutte le pagine ``sporche'' dei buffer),
	\item si scrive nel giornale/log la marca \texttt{CKP},
	\item si riprende l'esecuzione delle operazioni.
\end{enumerate}

\noindent Si scrive sul giornale una marca di inizio checkpoint che riporta l'elenco delle transazioni attive:\ $\mathtt{BeginCkp\ \{T_1,\dots,T_n\}}$.\
In parallelo alle normali operazioni delle transazioni, il gestore del buffer riporta sul disco tutte le pagine modificate.\
Si scrive sul giornale una marca di \texttt{EndCkp}, la quale certifica che tutte le scritture avvenute prima del \texttt{BeginCkp} ora sono sul disco.\

\begin{flushleft}
	Le scritture avvenute tra \texttt{BeginCkp} e \texttt{EndCkp} forse sono sul disco e forse no.
\end{flushleft}

\noindent In caso di fallimento di una \textbf{transazione} si scrive nel giornale $\langle\mathtt{T, abort}\rangle$ e si applica la procedura disfare.\

Se si verifica un fallimento di \textbf{sistema} la BD viene ripristinata con il comando \texttt{Restart} (ripartenza di emergenza), a partire dallo stato al punto di allineamento, procedendo come segue:\ \textit{le transazioni non terminate devono essere disfatte}, mentre \textit{le transazioni terminate devono essere rifatte}.\

Infine, nel caso di \textbf{disastro}, si riporta in linea la copia più recente della BD e la si aggiorna rifacendo le modifiche delle transazioni terminate normalmente (ripartenza a freddo).\

\subsubsection{Ripresa a caldo}
Garantisce atomicità e persistenza delle transazioni.\
Quattro fasi:
\begin{enumerate}
	\item trovare l'ultimo checkpoint (ripercorrendo il log a ritroso);
	\item costruire gli insiemi UNDO (transazioni da disfare) e REDO (transazioni da rifare);
	\item ripercorrere il log all'indietro, \textit{fino alla \textbf{più} vecchia azione} delle transazioni in UNDO, disfacendo tutte le azioni delle transazioni in UNDO;
	\item ripercorrere il log in avanti, rifacendo tutte le azioni delle transazioni in REDO.
\end{enumerate}

\subsubsection{Ripresa a freddo}
Risponde ad un guasto che provoca il deterioramento della BD:
\begin{enumerate}
	\item si ripristinano i dati a partire dal backup,
	\item si eseguono le operazioni registrate sul giornale fino all'istante del guasto,
	\item si esegue una ripresa a caldo.
\end{enumerate}

\section{Gestore della concorrenza}

Uno schedule \textbf{\textit{S}} si dice \textbf{seriale} se \textit{le azioni di ciascuna transazione appaiono in sequenza}, senza essere inframezzate da azioni di altre transazioni.
\[S=\{T_1, T_2,\dots, T_n\}\]
Schedule seriale ottenibile se:
\begin{itemize}
	\item Le transazioni sono \textit{eseguite uno alla volta} (scenario non realistico).
	\item Le transazioni sono \textit{completamente indipendenti} l'una dall'altra (improbabile).
\end{itemize}

\noindent In un sistema reale, le transazioni vengono eseguite in concorrenza per ragioni di efficienza/scalabilità.\
Tuttavia, l'esecuzione concorrente determina un insieme di \textbf{problematiche} che devono essere gestite; il DBMS deve garantire che l'esecuzione concorrente di transazioni avvenga senza interferenze in caso di accessi agli stessi dati.

Il DBMS transazionale gestisce questi problemi garantendo la proprietà di \textbf{isolamento}:\ garantisce che essa sia eseguita come se non ci fosse concorrenza.\
Questa proprietà è assicurata facendo in modo che ciascun insieme di transazioni concorrenti sottoposte al sistema sia ``\textbf{serializzabile}''.

\begin{definition}
	Un'esecuzione di un insieme di transazioni $\{T_1, \dots, T_n\}$ si dice \textbf{seriale} se, per ogni coppia di transazioni $T_i$ e $T_j$, tutte le operazioni di $T_i$ vengono eseguite prima di qualsiasi operazione $T_j$ o viceversa.
\end{definition}

\begin{definition}
	Un'esecuzione di un insieme di transazioni si dice \textbf{serializzabile} se produce lo stesso effetto sulla base di dati di quello ottenibile eseguendo serialmente, in un qualche ordine, le sole transazioni terminate normalmente.
\end{definition}

\noindent Nella pratica i DBMS implementano tecniche di controllo di concorrenza che garantiscono direttamente la serializzabilità delle transazioni concorrenti.\
Tali tecniche si dividono in due classi principali:
\begin{itemize}
	\item Protocolli \textbf{pessimistici}/conservativi:\ tendono a ``\textit{ritardare}'' l'esecuzione di transazioni che potrebbero generare conflitti, e quindi anomalie, rispetto alla transazione corrente.\ Cercano quindi di prevenire.
	\item Protocolli \textbf{ottimistici}:\ permettono l'esecuzione sovrapposta e non sincronizzata di transazioni ed effettuano un controllo sui possibili conflitti generati \textit{solo a valle del} \texttt{commit}.
\end{itemize}

\subsubsection{Controllo della concorrenza ottimistico}

Ogni transazione effettua ``liberamente'' le proprie operazioni sugli oggetti della base di dati secondo l'ordine temporale con cui le operazioni stesse sono generate.\
Al \texttt{commit} viene effettuato un controllo per stabilire se sono stati riscontrarti eventuali conflitti e nel caso viene effettuato il rollback delle azioni delle transazioni e la relativa riesecuzione.\
In generale, un protocollo di controllo di concorrenza ottimistico è basato su 3 fasi:

\begin{itemize}
	\item Fase di \textbf{lettura}:\ ogni transazione legge i valori degli oggetti della BD su cui deve operare e li memorizza in variabili (copie) locali dove sono effettuati eventuali aggiornamenti.
	\item Fase di \textbf{validazione}:\ vengono effettuati dei controlli sulla serializzabilità nel caso che gli aggiornamenti locali delle transazioni dovessero essere propagati sulla base di dati.
	\item Fase di \textbf{scrittura}:\ gli aggiornamenti delle transazioni che hanno superato la fase di validazione sono propagati definitivamente sugli oggetti della BD.
\end{itemize}

\subsubsection{Controllo della concorrenza pessimistico}

Nella pratica i DBMS implementano tecniche di controllo di concorrenza che garantiscono direttamente la serializzabilità delle transazioni concorrenti.\
Tali tecniche si dividono in due classi principali:\ metodi basati su \textit{lock} e metodi basati su \textit{timestamp}.\

I DMBS commerciali usano il meccanismo dei lock:\ blocca l'accesso ai dati ai quali una transazione accede ad altre transazioni.
\begin{itemize}
	\item Lock a \textit{livello di riga}, \textit{tabella}, \textit{pagina} (multi \textbf{granularità}).
	\item Lock in operazioni di scrittura (\textit{mutua esclusione}) e di lettura (\textit{accesso condiviso}) (\textbf{multimodale}).
\end{itemize}

\noindent Su ogni lock possono essere definite due operazioni:\ \textbf{richiesta} del lock in let\-tura{\slash}scrittura e \textbf{rilascio} del lock (unlock) acquisito in precedenza.\

In generale, quando una risorsa è bloccata, le transazioni che ne richiedono l'accesso vengono in genere messe in coda; quindi devono aspettare (che il lock sia rimosso).\
In sostanza, questo è un meccanismo efficace, ma influisce sulle prestazioni.\

\subsubsection{Serializzatore SPL Stretto}

Il gestore della concorrenza (serializzatore) dei DBMS ha il compito di stabilire l'ordine secondo il quale vanno eseguite le singole operazioni per rendere serializzabile l'esecuzione di un insieme di transazioni.

\begin{definition}
	Il protocollo del blocco a due fasi stretto (\textbf{Strict Two Phase Locking}) è definito dalle seguenti regole:
	\begin{itemize}
		\item ogni transazione, prima di effettuare un'operazione acquisisce il blocco corrispondente (chiede il lock);
		\item transazioni diverse non ottengono blocchi in conflitto;
		\item i blocchi/lock si rilasciano alla terminazione della transazione (cioè al \texttt{commit}/\texttt{abort}).
	\end{itemize}
\end{definition}

\noindent\textbf{Problema}:\ i protocolli 2PL possono generare schedule con situazioni di \textbf{deadlock} (\textbf{stallo}).

\vspace{12pt}

\noindent Per gestire le situazioni di \textit{deadlock} causate dal gestore della concorrenza, si possono usare tre tecniche:

\begin{enumerate}
	\item Uso dei \textbf{timeout}:\ \textit{ogni operazione di una transazione ha un timeout} entro il quale deve essere completata, \textit{pena annullamento} (\texttt{abort}) \textit{della transazione stessa}.
	\item \textbf{Deadlock avoidance}:\ prevenire le configurazioni che potrebbero portare ad un deadlock.\ Come?\ Eseguendo il \textbf{lock}/\textbf{unlock} di tutte le risorse allo stesso tempo, oppure utilizzando dei \textbf{time-stamp} o delle \textbf{classi di priorità} tra transazioni (può determinare \textit{starvation}\footnote{\textit{Starvation}:\ quando una transazione è impossibilitata a proseguire la sua esecuzione per un periodo di tempo indefinito, mentre le altre transazioni del sistema proseguono tranquillamente.}).
	\item\textbf{Deadlock detection}:\ utilizzare \textit{algoritmi per identificare eventuali situazioni di deadlock} e prevedere meccanismi di recovery dal deadlock. $\rightarrow$ Grafo delle richieste/risorse utilizzato per identificare la presenza di cicli (corrispondenti a deadlock); in caso di ciclo, si fa \texttt{abort} delle transazioni coinvolte nel ciclo in modo da eliminare la mutua dipendenza.\
\end{enumerate}

\subsubsection{Time-stamp delle transazioni}

Un metodo alternativo al 2PL per la gestione della concorrenza in un DBMS prevede l'utilizzo dei \textit{time-stamp delle transazioni} (metodo \textbf{TS}):\ ad ogni transazione si associa un \textbf{time-stamp} che rappresenta il momento di inizio della transazione; ogni transazione \textit{non può leggere o scrivere un dato scritto da una transazione con time-stamp maggiore} e \textit{non può scrivere su un dato già letto da una transazione con time-stamp maggiore}.

\subsubsection{Livelli di isolamento/consistenza per ogni transazione}

\texttt{SERIALIZABLE} assicura che la transazione T legga solo cambiamenti fatti da transazioni concluse (che hanno fatto il \texttt{commit}), che nessun valore letto o scritto da T verrà cambiato da altre transazione finché T non è conclusa e che se T legge un insieme di valori acceduti secondo qualche condizione di ricerca, l'insieme non viene modificato da altre transazione finché T non è conclusa.\

\texttt{REPEATABLE READ} assicura che la transazione T legga solo cambiamenti fatti da transazioni concluse (che hanno fatto il \texttt{commit}) e che nessun valore letto o scritto da T verrà cambiato da altre transazione finché T non è conclusa.\

\texttt{READ COMMITTED} assicura che la transazione T legga solo cambiamenti fatti da transazioni concluse (che hanno fatto il \texttt{commit}) e che T non veda nessun cambiamento eventualmente effettuato da transazioni concorrenti non concluse tra i valori letti all'inizio di T.\

\texttt{READ UNCOMMITTED}:\ a questo livello di isolamento una transazione T può leggere modifiche fatte ad un oggetto da un transazione in esecuzione; ovviamente l'oggetto può essere cambiato mentre T è in esecuzione.\
Quindi T è soggetta a effetti fantasma.
